# Data Pipeline: SQL Server to Apache Iceberg (Local Windows Cluster)

Este projeto demonstra a implementa√ß√£o de um pipeline de dados robusto e distribu√≠do, utilizando um cluster local **Apache Spark 3.5.7** no Windows para extra√ß√£o de dados de um **SQL Server** e carga em tabelas **Apache Iceberg** na **AWS (S3/Glue)**.

![Estrutura do projeto](img/projeto_spark.png)

## üèóÔ∏è Arquitetura e Especifica√ß√µes

* **Ambiente de Execu√ß√£o:** Windows 10/11 (Standalone Cluster: 1 Master + 2 Workers).
* **Engine de Processamento:** Apache Spark 3.5.7.
* **Linguagem:** Python 3.11 (Obrigat√≥rio para evitar instabilidade no Spark 3.5).
* **Orquestra√ß√£o de Metadados:** AWS Glue Data Catalog.
* **Storage Final:** AWS S3 (Formato Apache Iceberg).
* **Monitoramento:** Spark History Server com logs de eventos locais.

---

## üõ†Ô∏è Pr√©-requisitos no Windows

Para reproduzir este ambiente, siga estas etapas cruciais para o funcionamento no Windows:

1. **Hadoop Binaries:** Baixe o `winutils.exe` e `hadoop.dll` compat√≠veis com o Hadoop 3.3 e coloque-os na pasta `bin` dentro do seu `HADOOP_HOME`.
2. **Autentica√ß√£o SQL Server:** Para utilizar `integratedSecurity=true` (autentica√ß√£o Windows), voc√™ deve baixar o driver JDBC da Microsoft e copiar a biblioteca `mssql-jdbc_auth.dll` para a pasta `C:\Windows\System32`.
3. **Vari√°veis de Ambiente:**
* `SPARK_HOME`: Caminho da instala√ß√£o do Spark.
* `HADOOP_HOME`: Caminho da pasta que cont√©m os bin√°rios do Hadoop.
* `PYSPARK_PYTHON` & `PYSPARK_DRIVER_PYTHON`: Devem apontar para o execut√°vel do Python 3.11.



---

## ‚öôÔ∏è Configura√ß√£o do Spark (`spark-defaults.conf`)

O arquivo abaixo cont√©m as otimiza√ß√µes de mem√≥ria, paralelismo e integra√ß√£o com o ecossistema AWS/Iceberg:

```properties
# Performance & Serializer
spark.serializer                 org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max  512m
spark.network.timeout            800s
spark.sql.adaptive.enabled       true

# Cluster Resources (Standalone)
spark.executor.instances         2
spark.executor.cores             4
spark.executor.memory            5g
spark.driver.memory              2g

# Iceberg & AWS Glue Catalog
spark.sql.defaultCatalog         dev
spark.sql.catalog.dev            org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.dev.type       glue
spark.sql.catalog.dev.io-impl    org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.dev.warehouse  s3://seu-bucket-data-warehouse/tables/
spark.sql.extensions             org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# Spark History Server & Logs
spark.eventLog.enabled           true
spark.eventLog.dir               file:///C:/spark/spark-events
spark.history.ui.port            18080
spark.history.fs.logDirectory    file:///C:/spark/spark-events

```

---

## üöÄ Fluxo de Processamento (Python)

O pipeline segue um padr√£o de engenharia focado em performance e escalabilidade:

### 1. Extra√ß√£o Paralela (JDBC)

O script utiliza `partitionColumn`, `lowerBound` e `upperBound` para dividir a carga de trabalho entre os workers. Isso permite que o Spark realize m√∫ltiplas conex√µes simult√¢neas ao SQL Server, acelerando drasticamente o download de tabelas grandes.

### 2. Staging Local em Parquet

Antes de enviar os dados para a nuvem, os dados s√£o gravados em um storage local em formato **Parquet** com compress√£o **ZSTD**. Isso garante que, em caso de falha na rede durante o upload para o S3, os dados j√° foram extra√≠dos da origem com sucesso.

### 3. Escrita Iceberg & Otimiza√ß√µes

A carga no Iceberg utiliza as seguintes propriedades:

* **Merge-on-Read:** Otimiza o desempenho de escrita e atualiza√ß√µes.
* **Compression ZSTD:** Alta taxa de compress√£o com baixo overhead de CPU.
* **File Size (128MB):** Configura√ß√£o `write.target-file-size-bytes` para evitar o problema de "small files" no S3.

### 4. Manuten√ß√£o de Tabela

Ap√≥s a carga, o script executa automaticamente rotinas de manuten√ß√£o para garantir a sa√∫de do Lakehouse:

* `rewrite_data_files`: Compacta√ß√£o de arquivos pequenos.
* `expire_snapshots`: Limpeza de vers√µes antigas dos dados.
* `remove_orphan_files`: Remo√ß√£o de arquivos de dados que n√£o est√£o mais referenciados.

---

## üì¶ Bibliotecas Necess√°rias (JARs)

Certifique-se de que os seguintes pacotes estejam dispon√≠veis (via `spark.jars.packages` ou na pasta `jars` do Spark):

* `iceberg-spark-runtime-3.5_2.12`
* `iceberg-aws-bundle`
* `hadoop-aws`
* `mssql-jdbc`

---

## üìà Monitoramento

Para visualizar o progresso dos Jobs e analisar o hist√≥rico de execu√ß√£o:

1. Inicie o master e os workers locais.
2. Acesse a Spark UI em `http://localhost:8080`.
3. Acesse o History Server em `http://localhost:18080`.

---

**Nota:** Este projeto foi desenvolvido para ambientes de estudo e testes de carga local simulando pipelines produtivos de alta performance.
